
命名实体识别:

命名实体识别从早期基于词典和规则的方法，到传统机器学习的方法， 后来采用基于深度学习的方法，一直到当下热门的注意力机制、图神经网络等研究方法， 命名实体识别技术路线随着时间在不断发展。

![image](https://user-images.githubusercontent.com/36963108/178393815-01045ee4-885e-4aec-9231-c65cfa3af835.png)


https://github.com/TianRanPig/chinese_ner

https://github.com/CLUEbenchmark/CLUENER2020

https://github.com/hemingkx/CLUENER2020

https://github.com/lonePatient/BERT-NER-Pytorch

https://github.com/lemonhu/NER-BERT-pytorch

https://github.com/google-research/bert

https://github.com/TobiasLee/ChineseNER

https://github.com/PottermoreIron/BERT-BiLSTM-CRF-For-Practice

https://github.com/luopeixiang/named_entity_recognition

https://github.com/F-debug/Medical-named-entity-recognition

https://github.com/kyzhouhzau/BERT-NER

https://github.com/macanv/BERT-BiLSTM-CRF-NER

https://github.com/xuanzebi/BERT-CH-NER

https://github.com/huggingface/transformers

使用bert做领域分类、意图识别和槽位填充任务 https://github.com/xiaopp123/bert-joint-NLU

基于pytorch的中文意图识别和槽位填充 https://github.com/taishan1994/pytorch_bert_intent_classification_and_slot_filling

基于BERT+Tensorflow-1.15+Horovod-0.22的NLU（意图识别+槽位填充）分布式GPU训练模块 https://github.com/jx1100370217/JointBERT_nlu_tf

使用bert做领域分类、配置识别和位置填充任务 https://github.com/xiaopp123/bert-joint-NLU

中文语言理解基准、基准中文语言理解评估基准：数据集、预训练模型、语料库 https://github.com/CLUEbenchmark/CLUE

用于联合意图分类和插槽填充的 BERT https://github.com/monologg/JointBERT

https://github.com/yuanxiaosc/BERT-for-Sequence-Labeling-and-Text-Classification

https://github.com/pymacbit/BERT-Intent-Classification

https://github.com/ensembles4612/medical_intent_detector_using_BERT

https://github.com/AdamLouly/Intent-Classifier-using-BERT-and-TF2/blob/master/BERT2INTENT.ipynb

https://github.com/sz128/slot_filling_and_intent_detection_of_SLU

https://github.com/471417367/bert_intention_zh

数据集自动标注工具--释放AI潜力！https://www.modelfun.cn/home

实体识别数据集 https://github.com/juand-r/entity-recognition-datasets

ner综述： https://blog.csdn.net/weixin_45884316/article/details/118684681

使用 CLIP 将图像和句子嵌入到固定长度的向量中 https://github.com/jina-ai/clip-as-service


