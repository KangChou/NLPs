# NLPs
Deep learning speech learning library

一个轻量级、简单易用的 RNN 唤醒词监听器: [https://github.com/MycroftAI/mycroft-precise](https://github.com/MycroftAI/mycroft-precise)

zh:[http://fancyerii.github.io/books/mycroft-precise/](http://fancyerii.github.io/books/mycroft-precise/)

基于树莓派的人工智能小车，实现识别、提示、智能旅游线路、离线图像:
[https://github.com/dalinzhangzdl/AI_Car_Raspberry-pi](https://github.com/dalinzhangzdl/AI_Car_Raspberry-pi)

中文NLP数据集:[https://github.com/CLUEbenchmark/CLUEDatasetSearch](https://github.com/CLUEbenchmark/CLUEDatasetSearch) 

模型：[https://github.com/CLUEbenchmark/CLUE](https://github.com/CLUEbenchmark/CLUE) 

中文 NLP 资源精选列表 中文自然语言处理相关资料:
[https://github.com/crownpku/Awesome-Chinese-NLP](https://github.com/crownpku/Awesome-Chinese-NLP)

视觉聊天机器人:[https://paperswithcode.com/paper/visual-dialog](https://paperswithcode.com/paper/visual-dialog)

Bert/Transformer模型压缩与优化加速: https://blog.csdn.net/nature553863/article/details/120292394：

可以压缩 BERT 的所有方式：http://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.html
https://www.leiphone.com/category/academic/MkV1j604LvPt1wcx.html

BERT轻量化探索—模型剪枝（BERT Pruning）—Rasa维度剪枝:https://blog.csdn.net/ai_1046067944/article/details/103609152 

压缩 BERT 以加快预测速度:https://rasa.com/blog/compressing-bert-for-faster-prediction-2/

论文综述与BERT相关最新论文:[https://github.com/tomohideshibata/BERT-related-papers](https://github.com/tomohideshibata/BERT-related-papers)
